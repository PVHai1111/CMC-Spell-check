{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce1028-2b93-45bc-9e43-f284c696b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyvi import ViTokenizer\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216243ae-a9a4-4e57-8010-04c48fa4dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến tệp JSON chứa dữ liệu văn bản\n",
    "file_path = r'C:\\Users\\Admin\\Downloads\\data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8e581-c33f-4d39-9e6a-0d875d6ebd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách các từ dừng tiếng Việt\n",
    "stop_words = set([\"và\", \"là\", \"của\", \"có\", \"với\", \"cho\", \"để\", \"đến\", \"từ\", \"trong\", \"bởi\", \"một\", \"những\", \"các\", \"thì\"])\n",
    "\n",
    "# Hàm kiểm tra xem một từ có chứa ký tự đặc biệt hoặc là số hay không\n",
    "def contains_special_characters_or_numbers(word):\n",
    "    return bool(re.search(r'[\\d@#\\$%\\^&\\*\\.,\\+\\-\\/><\\?\\'\\\";:\\|\\\\[\\]\\{\\}~`\\!\\(\\)=]', word))\n",
    "\n",
    "# Loại bỏ các từ dừng, dấu câu và các từ chứa ký tự đặc biệt hoặc số\n",
    "def remove_stopwords_and_punctuation(tokens):\n",
    "    cleaned_tokens = [\n",
    "        word.lower() \n",
    "        for word in tokens.split() \n",
    "        if word.lower() not in stop_words \n",
    "        and word not in string.punctuation \n",
    "        and not contains_special_characters_or_numbers(word)\n",
    "    ]\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbb0b9-52a7-4805-a2d2-3d96c2b71f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc tệp JSON theo từng khối\n",
    "def process_json_file(file_path):\n",
    "    word_freq = Counter()\n",
    "    buffer_size = 1024 * 1024  # 1MB buffer size\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        buffer = ''\n",
    "        while True:\n",
    "            chunk = file.read(buffer_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            buffer += chunk\n",
    "            while True:\n",
    "                try:\n",
    "                    data, idx = json.JSONDecoder().raw_decode(buffer)\n",
    "                    if isinstance(data, dict):  # Kiểm tra nếu 'data' là dict\n",
    "                        word_freq.update(process_json_object(data))\n",
    "                    buffer = buffer[idx:].lstrip()\n",
    "                except ValueError:\n",
    "                    break\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7bc20-dc27-4e30-b5a8-c9052c7b6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xử lý từng đối tượng JSON\n",
    "def process_json_object(data):\n",
    "    word_freq = Counter()\n",
    "    try:\n",
    "        # Đảm bảo 'data' là đối tượng dict\n",
    "        if isinstance(data, dict):\n",
    "            print(f\"Processing object: {data}\")  # Debug print\n",
    "            ocr_data = data.get(\"OCR_data\", {})\n",
    "            documents = ocr_data.get(\"document\", [])\n",
    "            \n",
    "            for doc in documents:\n",
    "                # Kiểm tra điều kiện parentIndex\n",
    "                if doc.get(\"parentIndex\") != \"0.0.0.0.0.0.0.0.0.0.0\":\n",
    "                    text_value = doc.get(\"textValue\", \"\")\n",
    "                    if text_value:\n",
    "                        tokenized_document = ViTokenizer.tokenize(text_value)\n",
    "                        cleaned_tokens = remove_stopwords_and_punctuation(tokenized_document)\n",
    "                        word_freq.update(cleaned_tokens)\n",
    "        else:\n",
    "            print(f\"Unexpected data type: {type(data)}\")  # Debug print\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing JSON object: {e}\")\n",
    "    return word_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c7fb9-5ad8-4b77-a38a-db0fcde9aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng từ điển\n",
    "def build_dictionary(word_frequencies):\n",
    "    # Tính số lượng từ cần loại bỏ\n",
    "    num_words_to_remove = int(len(word_frequencies) * 0.3)\n",
    "    \n",
    "    # Sắp xếp từ theo tần suất xuất hiện tăng dần và loại bỏ 30% các từ xuất hiện ít nhất\n",
    "    sorted_words = sorted(word_frequencies.items(), key=lambda item: item[1])\n",
    "    filtered_words = sorted_words[num_words_to_remove:]\n",
    "    \n",
    "    # Xây dựng từ điển kết quả\n",
    "    dictionary = {word: freq for word, freq in filtered_words}\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f370d0d-b358-47fb-9096-52622c0e3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực hiện xử lý\n",
    "word_frequencies = process_json_file(file_path)\n",
    "print(f\"Word frequencies: {word_frequencies}\")  # In tần suất từ để kiểm tra\n",
    "dictionary = build_dictionary(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c8714-463b-4749-9e69-cc2488c0b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In từ điển kết quả\n",
    "print(f\"Số lượng từ trong từ điển: {len(dictionary)}\")\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41248467-a181-410b-8a7e-9d2d602b7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra chính tả đoạn văn bản\n",
    "def spell_check(text, dictionary):\n",
    "    tokenized_text = ViTokenizer.tokenize(text)\n",
    "    tokens = tokenized_text.split()\n",
    "    errors = []\n",
    "    \n",
    "    for idx, word in enumerate(tokens):\n",
    "        word_lower = word.lower()\n",
    "        if word_lower not in dictionary and not contains_special_characters_or_numbers(word_lower) and word_lower not in stop_words:\n",
    "            errors.append((word, idx))\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779414a-5e4d-445f-8707-f843db60eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đoạn văn bản cần kiểm tra chính tả\n",
    "input_text = \"tiền thuê đất djehd t43 giá cả htyk.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4ba4f-f8ae-49af-a1de-8ecc07abedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực hiện kiểm tra chính tả\n",
    "errors = spell_check(input_text, dictionary)\n",
    "\n",
    "# In ra các lỗi và vị trí lỗi\n",
    "if errors:\n",
    "    print(\"Các lỗi chính tả và vị trí:\")\n",
    "    for error in errors:\n",
    "        print(f\"Từ '{error[0]}' tại vị trí {error[1]}\")\n",
    "else:\n",
    "    print(\"Không có lỗi chính tả.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40e30f-f910-42b5-baf4-a9d050d9af41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
